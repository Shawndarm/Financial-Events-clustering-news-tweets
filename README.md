# Ã‰tapes 6 & 7 â€” Tweet Assignment + Alert Generation
## Projet Event Detection â€” Carta et al. (2021)
### Maeva & Roland â€” Master 2 MOSEF 2024-2025

---

## ğŸ“‚ Architecture du projet

```
task67/
â”‚
â”œâ”€â”€ notebooks/                          â† NOTEBOOKS JUPYTER (exÃ©cutÃ©s)
â”‚   â”œâ”€â”€ 6_tweet_assignment.ipynb        â† Ã‰tape 6 : Nettoyage + embedding + assignation tweets
â”‚   â””â”€â”€ 7_alert_generation.ipynb        â† Ã‰tape 7 : Ground truth + alertes + Ã©valuation P/R/F
â”‚
â”œâ”€â”€ src/                                â† MODULES PYTHON
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ tweet_preprocessing.py          â† Fonctions de nettoyage et embedding des tweets
â”‚   â”‚                                      â€¢ clean_tweet() : suppression RT, URLs, mentions, cashtags
â”‚   â”‚                                      â€¢ preprocess_tweet_spacy() : tokenisation spaCy
â”‚   â”‚                                      â€¢ compute_tweet_embedding() : GloVe 300d (mÃªme que news)
â”‚   â”‚                                      â€¢ load_lexicons_for_period() : charge les lexiques par dates
â”‚   â”‚                                      â€¢ run_tweet_embedding_pipeline() : pipeline complet
â”‚   â””â”€â”€ tweet_assignment.py             â† Fonctions d'assignation et d'Ã©valuation
â”‚                                          â€¢ assign_tweets_to_clusters() : cosine similarity â†’ seuil 0.5
â”‚                                          â€¢ compute_daily_assignment_ratio() : R(d) quotidien
â”‚                                          â€¢ generate_alerts() : R(d) > Î¸ â†’ alerte
â”‚                                          â€¢ build_ground_truth() : variation hebdo S&P 500 > 2%
â”‚                                          â€¢ evaluate_alerts() : Precision, Recall, F-score
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/                      â† DONNÃ‰ES TRAITÃ‰ES
â”‚   â”‚   â”œâ”€â”€ tweets_2023.csv             â† 2,243 tweets financiers (Maeva â€” Kaggle + VADER)
â”‚   â”‚   â”œâ”€â”€ sp500_2023.csv              â† 271 jours de trading S&P 500 (Roland â€” Yahoo Finance)
â”‚   â”‚   â””â”€â”€ lexicons_filtered/          â† 43 lexiques quotidiens filtrÃ©s P20/P80 (Roland)
â”‚   â”‚       â”œâ”€â”€ lexicon_filtered_2023-02-03.csv    â† DÃ©but : 28j avant la pÃ©riode d'analyse
â”‚   â”‚       â”œâ”€â”€ ...                                 (26 fichiers fÃ©vrier)
â”‚   â”‚       â”œâ”€â”€ lexicon_filtered_2023-03-03.csv    â† DÃ©but pÃ©riode SVB
â”‚   â”‚       â”œâ”€â”€ ...                                 (17 fichiers mars)
â”‚   â”‚       â””â”€â”€ lexicon_filtered_2023-03-17.csv    â† Fin pÃ©riode d'analyse
â”‚   â”‚
â”‚   â””â”€â”€ for_models/                     â† DONNÃ‰ES POUR LES MODÃˆLES
â”‚       â”œâ”€â”€ final_event_signatures.csv  â† CentroÃ¯des des 2 clusters (Roland â€” mÃ©diane, 300D)
â”‚       â”œâ”€â”€ clean_news_week_SVB.csv     â† 22 articles clustÃ©risÃ©s du 3-9 mars (Roland)
â”‚       â””â”€â”€ output/                     â† RÃ‰SULTATS INTERMÃ‰DIAIRES (Maeva)
â”‚           â”œâ”€â”€ tweets_assigned.csv     â† 550 tweets avec cluster assignÃ© + similaritÃ©
â”‚           â””â”€â”€ daily_assignment_ratios.csv  â† Ratio quotidien d'assignation (10 jours)
â”‚
â”œâ”€â”€ outputs/                            â† RÃ‰SULTATS FINAUX (graphiques + tableaux)
â”‚   â”œâ”€â”€ tweet_similarity_distribution.png  â† Distribution des similaritÃ©s cosinus
â”‚   â”œâ”€â”€ daily_assignment_ratio.png         â† % tweets assignÃ©s par jour + date SVB
â”‚   â”œâ”€â”€ sp500_ground_truth.png             â† S&P 500 avec event days en rouge
â”‚   â”œâ”€â”€ alert_generation.png               â† Alertes vs Ã©vÃ©nements
â”‚   â”œâ”€â”€ precision_recall_fscore.png        â† Courbes P/R/F vs seuil
â”‚   â”œâ”€â”€ evaluation_results.csv             â† MÃ©triques pour chaque seuil (1%-40%)
â”‚   â”œâ”€â”€ comparison_table.csv               â† Tableau comparatif avec Carta et al.
â”‚   â””â”€â”€ alerts_best_threshold.csv          â† Alertes au meilleur seuil
â”‚
â””â”€â”€ requirements.txt                    â† DÃ©pendances Python
```

---

## ğŸ“Š RÃ©sumÃ© des rÃ©sultats

### Ã‰tape 6 â€” Tweet Assignment

| MÃ©trique | Valeur |
|----------|--------|
| Tweets analysÃ©s (pÃ©riode 3-17 mars) | 163 aprÃ¨s nettoyage |
| Tweets avec embedding valide | ~550 (aprÃ¨s dÃ©doublonnage + spaCy) |
| Taux d'assignation (seuil 0.5) | **100%** |
| SimilaritÃ© moyenne | ~0.90 |
| Clusters | 2 (cluster 0 : 3 articles, cluster 1 : 19 articles) |

### Ã‰tape 7 â€” Alert Generation

| Seuil | Alertes | Precision | Recall | F-score |
|-------|---------|-----------|--------|---------|
| 1% Ã  40% | 10/10 jours | 80% | 5.6% | 10.4% |

Les mÃ©triques sont **identiques pour tous les seuils** car le ratio d'assignation est Ã  100% chaque jour.

### Comparaison avec le papier

| MÃ©trique | Carta et al. (2021) | Notre projet |
|----------|-------------------|--------------|
| Articles clustÃ©risÃ©s | 8,403 | 22 |
| Tweets | 283,473 | 163 |
| PÃ©riode | 4 ans (2016-2020) | 10 jours (mars 2023) |
| Recall (seuil 3%) | ~70% | 6% |
| Precision (seuil 3%) | ~55% | 80% |
| F-score (seuil 3%) | ~60% | 10% |
| Nb Ã©vÃ©nements GT | ~25 | 18 |
| % event days | ~15% | 38% |

---

## ğŸ” Analyse critique â€” Pourquoi les rÃ©sultats diffÃ¨rent du papier

### 1. Taux d'assignation Ã  100% : pourquoi ?

Le papier obtient un taux d'assignation de **15-30%** car ses 283K tweets Stocktwits sont trÃ¨s variÃ©s (spam, hors-sujet, langage informel). Le filtre cosinus Ã  0.5 Ã©limine naturellement les tweets non pertinents.

Dans notre cas, les **193 tweets** sont dÃ©jÃ  prÃ©-filtrÃ©s sur les cashtags S&P 500 ($SPY, $SPX). AprÃ¨s filtrage par le lexique (mots Ã  impact marchÃ© uniquement) et embedding GloVe, leur vocabulaire est tellement concentrÃ© sur le domaine financier que **tous** convergent vers les centroÃ¯des avec une similaritÃ© > 0.5 (la plupart entre 0.85 et 0.98).

â†’ **Le filtre de similaritÃ© ne discrimine plus rien.**

### 2. Precision Ã©levÃ©e (80%) mais Recall faible (6%)

- **Precision = 80%** : 8 des 10 jours d'alerte tombent dans un event day. C'est Ã©levÃ© car 2023 a Ã©tÃ© volatile (38% d'event days vs 15% dans le papier).
- **Recall = 6%** : nos 10 jours d'alerte ne couvrent que 1 Ã©vÃ©nement sur 18. Normal : on n'a des tweets que sur 10 jours (3-17 mars), mais la ground truth couvre toute l'annÃ©e 2023 (18 Ã©vÃ©nements).

### 3. Ce qui est respectÃ© vs ce qui est limitÃ©

**âœ… MÃ©thodologie respectÃ©e fidÃ¨lement :**
- Nettoyage tweets (RT, URLs, mentions, cashtags) â€” papier Â§8
- MÃªme espace sÃ©mantique (GloVe Dolma 300d) pour news et tweets â€” papier Â§4 + Â§8
- Filtrage par le lexique quotidien (P20/P80) â€” papier Â§3
- Assignation par cosine similarity, seuil 0.5 â€” papier Â§8
- Ground truth : variation hebdo S&P 500 > 2%, gap tolerance 3j â€” papier Â§10.2
- Ã‰valuation : Precision / Recall / F-score â€” papier Â§10.3
- Test multi-seuil (1% Ã  40%) â€” papier Â§10

**âš ï¸ Limites liÃ©es aux donnÃ©es :**
- 163 tweets vs 283K dans le papier (Ã—1,700 de moins)
- 22 articles sur 1 semaine vs 8,403 sur 4 ans
- 2 clusters fixes vs k optimal par silhouette (2-10)
- Tweets prÃ©-filtrÃ©s sur le domaine â†’ seuil de similaritÃ© inefficace
- Ground truth annuelle vs alertes sur 10 jours seulement
---

## â–¶ï¸ Comment reproduire

1. Installer les dÃ©pendances : `pip install -r requirements.txt`
2. Installer spaCy : `python -m spacy download en_core_web_sm`
3. Placer le modÃ¨le GloVe dans `models/` (non inclus, 4 Go)
4. ExÃ©cuter `notebooks/6_tweet_assignment.ipynb`
5. ExÃ©cuter `notebooks/7_alert_generation.ipynb`

---

## ğŸ“Œ Fichiers de Roland utilisÃ©s

| Fichier | Description | Produit par |
|---------|------------|-------------|
| `final_event_signatures.csv` | 2 centroÃ¯des Ã— 300D (mÃ©diane des clusters) | Roland â€” Ã‰tape 3-4 |
| `clean_news_week_SVB.csv` | 22 articles du 3-9 mars avec labels Cluster (0 ou 1) | Roland â€” Ã‰tape 3 |
| `lexicons_filtered/` | 43 lexiques quotidiens (3 fÃ©v â†’ 17 mars) | Roland â€” Ã‰tape 1 |
| `sp500_2023.csv` | Prix S&P 500, 271 jours de trading | Roland â€” Ã‰tape 0 |
