# Event Detection in Finance by Clustering News and Tweets üìàüì∞

![Python Badge](https://img.shields.io/badge/Python-3.10%2B-blue)
![Data Science Badge](https://img.shields.io/badge/Data_Science-NLP_%7C_Clustering-orange)
![Academic Badge](https://img.shields.io/badge/Universit√©_Paris_1-Panth√©on_Sorbonne-maroon)

**Authors:** Roland DUTAUZIET & Maeva N'GUESSAN
**Program:** Master 2 MOSEF - Data Science (Mod√©lisations Statistiques √âconomiques et Financi√®res) - 2025/2026  
**Context:** Quantitative Finance Project

## üìñ Project Overview

This project is a reproduction and an extension of the academic paper *"Event Detection in Finance by Clustering News and Tweets"* (Carta et al., 2021). The core objective is to build a robust NLP pipeline capable of detecting major financial events by clustering professional news articles, and then validating these events by measuring the "Social Heat" (public attention) through social media platforms (Twitter/Stocktwits).

We applied this methodology to the **S&P 500 index for the year 2023**, a period marked by high volatility, including the Silicon Valley Bank (SVB) collapse and and the ARM IPO.



---

## üèóÔ∏è Project Architecture

The repository is structured to ensure reproducibility and clean code separation.

```text
Financial-Events-clustering-news-tweets
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ for_models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ output/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ table_3_tweet_assignment_AI.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Tweet-to-cluster assignment results for the AI enthusiasm period (May‚ÄìJuly 2023).
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Used for quantitative evaluation and representative tweet analysis.
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ table_3_tweet_assignment_SVB.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Tweet assignment results for the Silicon Valley Bank crisis period (March 2023).
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Contains cosine similarity scores and assigned event IDs.
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clean_news_week_AI.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Preprocessed weekly news dataset for the AI event window.
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clean_news_week_SVB.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Preprocessed weekly news dataset for the SVB crisis window.
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_event_signatures_AI.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Median-based centroids (event signatures) after outlier removal (AI period).
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ final_event_signatures_SVB.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Robust cluster centroids after cleaning (SVB period).
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ news_features.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # 300-dimensional document embeddings (GloVe) for each news article.
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tweets_assigned.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Full tweet assignment output across all periods.
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tweets_assigned_AI.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Tweets assigned to clusters during AI enthusiasm period.
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tweets_assigned_SVB.csv
‚îÇ   ‚îÇ   ‚îÇ   ‚îÇ   # Tweets assigned to clusters during SVB crisis.
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tweets_features.csv
‚îÇ   ‚îÇ   ‚îÇ       # 300-dimensional embeddings for tweets (same GloVe model as news).
‚îÇ   ‚îÇ   ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ daily_dtm/
‚îÇ   ‚îÇ       ‚îÇ   # Daily binary Document-Term Matrices used for Marginal Screening.
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ daily_lexicons_filtered/
‚îÇ   ‚îÇ       ‚îÇ   # Daily filtered lexicons (P20/P80 percentile selection).
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ daily_lexicons_full/
‚îÇ   ‚îÇ       ‚îÇ   # Full lexicons before percentile filtering.
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ news_2023.csv
‚îÇ   ‚îÇ       ‚îÇ   # 1,565 financial news articles (GDELT, Yahoo Finance, CNBC).
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ news_2023_clean.csv
‚îÇ   ‚îÇ       ‚îÇ   # Cleaned and preprocessed version of news_2023.csv.
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ sp500_2023.csv
‚îÇ   ‚îÇ       ‚îÇ   # Daily S&P 500 prices (271 trading days). Used for return computation and ground truth.
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ tweets_2023.csv
‚îÇ   ‚îÇ           # 2,243 filtered financial tweets mentioning $SPX, $SPY, or S&P 500.
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ P10 Event detection in finance using ...
‚îÇ   ‚îÇ   # Original reference paper (Carta et al., 2021).
‚îÇ   ‚îú‚îÄ‚îÄ Rapport_Event_detection_Roland_...
‚îÇ   ‚îÇ   # Full academic report (methodology, results, evaluation).
‚îÇ   ‚îî‚îÄ‚îÄ Slides Finance quantitative.pdf
‚îÇ       # Presentation slides summarizing the project.
‚îÇ
‚îú‚îÄ‚îÄ img/
‚îÇ   ‚îú‚îÄ‚îÄ 1_lexicon_generation/
‚îÇ   ‚îÇ   # Marginal Screening plots and percentile threshold visualizations.
‚îÇ   ‚îú‚îÄ‚îÄ 2_feature_engineering/
‚îÇ   ‚îÇ   # Embedding illustrations and vector representations.
‚îÇ   ‚îú‚îÄ‚îÄ 3_news_clustering/
‚îÇ   ‚îÇ   # Silhouette scores, dendrograms, t-SNE visualizations.
‚îÇ   ‚îú‚îÄ‚îÄ 4_outlier_removal/
‚îÇ   ‚îÇ   # Cluster cleaning and centroid repositioning figures.
‚îÇ   ‚îú‚îÄ‚îÄ 5_relevant_words_extraction/
‚îÇ   ‚îÇ   # TF-IDF keyword extraction results per cluster.
‚îÇ   ‚îú‚îÄ‚îÄ 6_tweets_assignment/
‚îÇ   ‚îÇ   # Tweet-to-cluster similarity visualizations.
‚îÇ   ‚îú‚îÄ‚îÄ 7_alert_generation/
‚îÇ   ‚îÇ   # Alert ratio plots and ground truth comparisons.
‚îÇ   ‚îú‚îÄ‚îÄ 6_tweets_assignment.zip
‚îÇ   ‚îÇ   # Archived visual results for tweet assignment.
‚îÇ   ‚îî‚îÄ‚îÄ 7_alert_generation.zip
‚îÇ       # Archived visual results for alert generation.
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 0_extract_data.ipynb
‚îÇ   ‚îÇ   # Data ingestion, preprocessing, sentiment computation (VADER).
‚îÇ   ‚îú‚îÄ‚îÄ 1_lexicon_generation.ipynb
‚îÇ   ‚îÇ   # Implementation of Marginal Screening and daily lexicon construction.
‚îÇ   ‚îú‚îÄ‚îÄ 2_feature_engineering.ipynb
‚îÇ   ‚îÇ   # GloVe embedding computation and document vector construction.
‚îÇ   ‚îú‚îÄ‚îÄ 3_news_clustering.ipynb
‚îÇ   ‚îÇ   # Hierarchical clustering (HAC), silhouette maximization, centroid computation.
‚îÇ   ‚îú‚îÄ‚îÄ 4_outlier_removal.ipynb
‚îÇ   ‚îÇ   # Double-criterion outlier removal (silhouette + cosine similarity).
‚îÇ   ‚îú‚îÄ‚îÄ 5_relevant_words_extraction.ipynb
‚îÇ   ‚îÇ   # TF-IDF keyword extraction per cluster.
‚îÇ   ‚îú‚îÄ‚îÄ 6_tweet_assignment.ipynb
‚îÇ   ‚îÇ   # Tweet embedding and cosine similarity-based assignment.
‚îÇ   ‚îî‚îÄ‚îÄ 7_Alert_generation.ipynb
‚îÇ       # Alert computation, ground truth construction, Precision/Recall/F-score evaluation.
‚îÇ
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __pycache__/
‚îÇ   ‚îÇ   # Compiled Python bytecode (ignored by git).
‚îÇ   ‚îú‚îÄ‚îÄ alert_generation.py
‚îÇ   ‚îÇ   # Computes daily assignment ratio R(d), generates alerts (R(d) > Œ∏),
‚îÇ   ‚îÇ   # builds S&P 500 ground truth (|weekly return| > 2%), and evaluates Precision/Recall/F-score.
‚îÇ   ‚îú‚îÄ‚îÄ extract_data.py
‚îÇ   ‚îÇ   # Handles dataset loading, cleaning, date alignment,
‚îÇ   ‚îÇ   # tweet filtering by cashtags, and sentiment scoring (VADER).
‚îÇ   ‚îú‚îÄ‚îÄ feature_engineering.py
‚îÇ   ‚îÇ   # Filters articles using daily lexicons and computes 300D GloVe embeddings.
‚îÇ   ‚îú‚îÄ‚îÄ lexicon_generation.py
‚îÇ   ‚îÇ   # Builds daily binary DTM, computes Marginal Screening f(j),
‚îÇ   ‚îÇ   # selects positive/negative financial terms via percentile thresholds.
‚îÇ   ‚îú‚îÄ‚îÄ news_clustering.py
‚îÇ   ‚îÇ   # Runs Agglomerative Clustering (cosine + average linkage),
‚îÇ   ‚îÇ   # compares with K-Means/K-Medians, computes silhouette scores,
‚îÇ   ‚îÇ   # and calculates median-based centroids (event signatures).
‚îÇ   ‚îú‚îÄ‚îÄ outlier_removal.py
‚îÇ   ‚îÇ   # Applies double filtering: per-sample silhouette + centroid cosine similarity.
‚îÇ   ‚îÇ   # Removes noisy articles and recalculates centroids.
‚îÇ   ‚îú‚îÄ‚îÄ relevant_words_extraction.py
‚îÇ   ‚îÇ   # Computes TF-IDF within each cluster to extract top representative financial terms.
‚îÇ   ‚îî‚îÄ‚îÄ tweet_assignment.py
‚îÇ       # Embeds tweets using the same GloVe model,
‚îÇ       # assigns them to nearest event centroids via cosine similarity (threshold = 0.5).
‚îÇ
‚îú‚îÄ‚îÄ .gitignore
‚îÇ   # Excludes large data files, virtual environments, and cache folders.
‚îÇ
‚îú‚îÄ‚îÄ .python-version
‚îÇ   # Specifies Python interpreter version for reproducibility.
‚îÇ
‚îú‚îÄ‚îÄ LICENSE
‚îÇ   # Project license.
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îÇ   # Project documentation and methodological overview.
‚îÇ
‚îú‚îÄ‚îÄ pyproject.toml
‚îÇ   # Project metadata and dependency management (uv-compatible).
‚îÇ
‚îî‚îÄ‚îÄ uv.lock
    # Locked dependency versions ensuring reproducible environments.
```

---

## Installation & Setup

We use uv, an extremely fast Python package and project manager written in Rust, to handle our virtual environment and dependencies.

### 1. Install uv
If you haven't installed uv yet, run:

```Bash
# On Windows (PowerShell)
pip install uv
# On macOS/Linux
curl -LsSf [https://astral.sh/uv/install.sh](https://astral.sh/uv/install.sh) | sh
```
### 2. Setup the Virtual Environment
Navigate to the project directory, create and activate the environment:

```Bash
cd Financial-Events-clustering-news-tweets
uv venv
# Windows:
 .venv\Scripts\activate
# macOS/Linux:
source .venv/bin/activate
```
3. Install Dependencies
Install the required packages (Pandas, Numpy, Scikit-learn, Plotly, SciPy, Gensim):

```Bash
uv sync
```

---
Methodology & Pipeline StepsOur pipeline follows the 7 steps detailed by Carta et al. Below is the breakdown of each phase applied to our 2023 dataset.Step 1: Lexicon GenerationTo filter out noise and focus on financially meaningful text, we generated a domain-specific lexicon. We computed a Document-Term Matrix (DTM) and used Marginal Screening to select words with high predictive correlation to market movements, avoiding standard stop-words.Insert Screenshot: Word cloud or Lexicon distribution chart here.Step 2: Feature Engineering (Embeddings)We transformed raw text into dense mathematical vectors using Word2Vec.Texts were tokenized.Words outside the generated Lexicon were discarded.The remaining valid Word2Vec vectors were averaged to create a single Document Embedding for each news article.Step 3: News ClusteringWe tested four clustering algorithms: K-Means, Agglomerative Clustering (HAC), DBSCAN, and Gaussian Mixture Models (GMM). We optimized the number of clusters (k) by maximizing the Silhouette Score. Consistent with our report, HAC yielded the best results, forming dense and coherent groups of news.Insert Screenshot: Silhouette Score maximization chart or t-SNE plot (Figure 13a).Step 4: Relevant Words Extraction & Outlier RemovalNot all news clusters represent financial events. We computed the Average TF-IDF for each cluster to extract its top relevant words. Clusters lacking strong financial terminology were classified as "Outliers" and discarded.Insert Screenshot: Bar charts of Key Financial Terms (Figure 14).Step 5: Event SignaturesFor the remaining valid clusters, we computed the Centroid (the mathematical average of all document vectors in that cluster). This centroid becomes the "Signature" of the event, acting as a gravitational pull for the upcoming social media analysis.Insert Screenshot: Cleaned Clusters with Centroids (Figure 13b).Step 6: Tweet AssignmentTo gauge public attention, we linked social media data to the professional news.De-duplication: Removed spam and bot-generated identical tweets.Cosine Similarity: Measured the distance between a tweet's embedding and the Event Signatures.Threshold (delta): Tweets with a similarity score above the delta threshold were assigned to the event.Insert Screenshot: Distribution of Tweet Assignments (Figure 15).Step 7: Alert Generation & EvaluationAn alert is generated if the "Social Heat" (the ratio of assigned tweets to the total daily tweets) exceeds a specific threshold.To evaluate the model's accuracy, we calculated a Ground Truth based on the S&P 500 weekly variation:$$ \Delta_d = \frac{|close(d+7) - close(d)|}{close(d)} $$Days with $\Delta_d > 0.02$ were marked as event intervals. We then computed Precision, Recall, and F-Score.Insert Screenshot: Plotly chart showing the S&P 500 price with Ground Truth zones and social alerts.Case Studies (2023)Our pipeline successfully detected major market shifts in 2023:The Silicon Valley Bank (SVB) Collapse (March 2023): Detected a massive spike in Social Heat just prior to the heavy market drawdown.The AI Boom & Nvidia (May 2023): Captured the technological hype translating into market momentum.ARM IPO (September 2023): Tracked the anticipation and immediate aftermath of a major tech listing.Key FindingsHAC Dominance: Hierarchical Agglomerative Clustering outperformed K-means and DBSCAN in creating semantically meaningful clusters.Recall over Precision: In a trading context, missing a crash (low recall) is worse than a false alarm (low precision). Our algorithm successfully captures almost all ground truth events.Social Hype Delay: The pipeline demonstrated that while news breaks instantly, the "Social Heat" sometimes anticipates or slightly lags behind the price impact, providing valuable alpha.AcknowledgmentsOriginal Authors: Carta, S., et al. (2021). Event Detection in Finance by Clustering News and Tweets.Institution: Universit√© Paris 1 Panth√©on-Sorbonne (Master MOSEF).
