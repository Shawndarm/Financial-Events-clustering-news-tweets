{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfcdb5c2",
   "metadata": {},
   "source": [
    "# Lexicon Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee78fd78",
   "metadata": {},
   "source": [
    "The objective is to identify relevant words for finacial markets. \n",
    "To achieve this, \n",
    "\n",
    "\n",
    "\n",
    "- Objectif : Identifier les mots qui ont un impact réel sur le marché financier.\n",
    "- Procédure : \n",
    "    - Prendre les articles de presse sur une fenêtre de 4 semaines précédant le jour $d$.\n",
    "    - Calculer la corrélation de chaque mot avec la variation du prix de l'indice ($\\Delta$) le jour suivant sa publication.\n",
    "    - Filtrage des mots trop fréquents (>90% des documents) ou trop rares (<10 documents).\n",
    "    - Sélection des mots situés dans les percentiles extrêmes (les plus positifs et les plus négatifs) pour former le lexique \"conscient du temps\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1bd8c9",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a86d7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.lexicon_generation import preprocess_spacy, build_daily_lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40d918",
   "metadata": {},
   "source": [
    "### Data Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0a2df9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "news = pd.read_csv('../data/processed/news_2023.csv')\n",
    "tweets = pd.read_csv('../data/processed/tweets_2023.csv')\n",
    "prices = pd.read_csv('../data/processed/sp500_2023.csv', skiprows=3, names=['date', 'close', 'high', 'low', 'open', 'vol', 'returns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5b415655",
   "metadata": {},
   "outputs": [],
   "source": [
    "news['date'] = pd.to_datetime(news['date']).dt.date\n",
    "prices['date'] = pd.to_datetime(prices['date']).dt.date\n",
    "prices_map = prices.set_index('date')['returns'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3290a69",
   "metadata": {},
   "source": [
    "### Lexicon generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "nlp = spacy.blank(\"en\")\n",
    "LEXICON_OUTPUT_DIR = '../data/processed/daily_lexicons/'\n",
    "DTM_OUTPUT_DIR = '../data/processed/daily_dtm/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e1e6d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Pre-processing text...\n"
     ]
    }
   ],
   "source": [
    "print(\"Step 1: Pre-processing text...\")\n",
    "news['clean'] = (news['headline'] + \" \" + news['body']).apply(lambda x: preprocess_spacy(x, nlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8236be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Generating Daily Lexicons (Rolling Window)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:43<00:00,  7.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Daily Loop (Rolling Window)\n",
    "results = []\n",
    "start_d = pd.to_datetime('2023-01-29').date()\n",
    "end_d = pd.to_datetime('2023-12-31').date()\n",
    "\n",
    "print(\"Step 2: Generating Daily Lexicons (Rolling Window)...\")\n",
    "for current_date in tqdm(pd.date_range(start_d, end_d)):\n",
    "    d = current_date.date()   \n",
    "    # Collection of articles in window [d-28, d-1]\n",
    "    window_news = news[(news['date'] >= d - timedelta(days=28)) & (news['date'] < d)].copy()  \n",
    "    # Build Lexicon\n",
    "    lex_map = build_daily_lexicon(window_news, prices_map, d, LEXICON_OUTPUT_DIR, DTM_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet_Roland_Maeva",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
